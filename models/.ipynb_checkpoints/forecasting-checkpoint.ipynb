{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7183c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_124963/4021243019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeseriesGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from IPython.display import Image, display\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (10,8)\n",
    "mpl.rcParms['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deaa8d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>flightNumber</th>\n",
       "      <th>craftTypeCode</th>\n",
       "      <th>depAirport</th>\n",
       "      <th>traAirport</th>\n",
       "      <th>arrAirport</th>\n",
       "      <th>departureDate</th>\n",
       "      <th>arrivalDate</th>\n",
       "      <th>cabinClass</th>\n",
       "      <th>priceClass</th>\n",
       "      <th>price</th>\n",
       "      <th>rate</th>\n",
       "      <th>createDate</th>\n",
       "      <th>dateDifference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14393</td>\n",
       "      <td>HO1252</td>\n",
       "      <td>320</td>\n",
       "      <td>PEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHA</td>\n",
       "      <td>2019-01-04 06:35:00</td>\n",
       "      <td>2019-01-04 08:55:00</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1860</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2019-01-03 14:26:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14409</td>\n",
       "      <td>MU5138</td>\n",
       "      <td>33L</td>\n",
       "      <td>PEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHA</td>\n",
       "      <td>2019-01-04 07:00:00</td>\n",
       "      <td>2019-01-04 09:15:00</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>1640</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2019-01-03 14:26:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14415</td>\n",
       "      <td>MU5138</td>\n",
       "      <td>33L</td>\n",
       "      <td>PEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHA</td>\n",
       "      <td>2019-01-04 07:00:00</td>\n",
       "      <td>2019-01-04 09:15:00</td>\n",
       "      <td>C</td>\n",
       "      <td>J</td>\n",
       "      <td>5360</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2019-01-03 14:26:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14429</td>\n",
       "      <td>HU7605</td>\n",
       "      <td>350</td>\n",
       "      <td>PEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHA</td>\n",
       "      <td>2019-01-04 07:20:00</td>\n",
       "      <td>2019-01-04 09:35:00</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>1635</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2019-01-03 14:26:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14431</td>\n",
       "      <td>HU7605</td>\n",
       "      <td>350</td>\n",
       "      <td>PEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHA</td>\n",
       "      <td>2019-01-04 07:20:00</td>\n",
       "      <td>2019-01-04 09:35:00</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>1640</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2019-01-03 14:26:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID flightNumber craftTypeCode depAirport traAirport arrAirport  \\\n",
       "0  14393       HO1252           320        PEK        NaN        SHA   \n",
       "1  14409       MU5138           33L        PEK        NaN        SHA   \n",
       "2  14415       MU5138           33L        PEK        NaN        SHA   \n",
       "3  14429       HU7605           350        PEK        NaN        SHA   \n",
       "4  14431       HU7605           350        PEK        NaN        SHA   \n",
       "\n",
       "         departureDate          arrivalDate cabinClass priceClass  price  \\\n",
       "0  2019-01-04 06:35:00  2019-01-04 08:55:00          C          C   1860   \n",
       "1  2019-01-04 07:00:00  2019-01-04 09:15:00          C          I   1640   \n",
       "2  2019-01-04 07:00:00  2019-01-04 09:15:00          C          J   5360   \n",
       "3  2019-01-04 07:20:00  2019-01-04 09:35:00          C          I   1635   \n",
       "4  2019-01-04 07:20:00  2019-01-04 09:35:00          C          I   1640   \n",
       "\n",
       "   rate           createDate  dateDifference  \n",
       "0  1.00  2019-01-03 14:26:15               1  \n",
       "1  0.31  2019-01-03 14:26:15               1  \n",
       "2  1.00  2019-01-03 14:26:15               1  \n",
       "3  0.29  2019-01-03 14:26:15               1  \n",
       "4  0.29  2019-01-03 14:26:15               1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../_data/pek-sha.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8027b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'F', 'Y'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['cabinClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1237ade3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['flightNumber']=='MU5138') & (df['departureDate']=='2019-01-07 07:00:00')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed48a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class Forecasting:\n",
    "    def __init__(self, df:pd.DataFrame, target):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.tts = dict()\n",
    "        self.window_size = 5\n",
    "        \n",
    "    def data_to_X_y(self, data, window_size=5):\n",
    "        data_as_np = data.to_numpy()\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(len(data_as_np)-window_size):\n",
    "            row = [[a] for a in data_as_np[i:i+5]]\n",
    "            X.append(row)\n",
    "            label = data_as_np[i+5]\n",
    "            y.append(label)\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def split_train_test(self, X, y, train, test, validation):\n",
    "        self.tts['xtrain'], self.tts['ytrain'] = X[:train], y[:train]\n",
    "        self.tts['xtest'], self.tts['ytest'] = X[:test], y[:test]\n",
    "        self.tts['xval'], self.tts['yval'] = X[:validation], y[:validation]\n",
    "        \n",
    "    def prepareLSTMForecasting(self, date_column, window_size=5, train_split, test_split, validation_split):\n",
    "        # transform date column to index\n",
    "        self.df.index = pd.to_datetime(self.df[date_column], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # create time series\n",
    "        if window_size:\n",
    "            self.window_size = window_size\n",
    "        X, y = self.data_to_X_y(self.df[self.target], window_size=self.window_size)\n",
    "        print(X.shape, y.shape)\n",
    "        \n",
    "        # splitting data\n",
    "        self.split_train_test(X, y, train_split, test_split, validation_split)\n",
    "\n",
    "    def plotForecasting(self, x, y):\n",
    "        plt.plot(x)\n",
    "        plt.plot(y)\n",
    "        plt.show()\n",
    "        \n",
    "    def saveModel(self, model, title):\n",
    "        path_pickle = 'saved models/'+title+'.pkl'\n",
    "        path_joblib = 'saved models/'+title+'.sav'\n",
    "        pickle.dump(model, open(path_pickle, 'wb'))\n",
    "        joblib.dump(model, open(path_joblib, 'wb'))\n",
    "        print('model saved at',path_pickle,'and',path_joblib)\n",
    "    \n",
    "    def LSTMforecasting(self, epochs=5, plot=False):\n",
    "        model = Sequential()\n",
    "        model.add(InputLayer((self.window_size,1)))\n",
    "        model.add(LSTM(64))\n",
    "        model.add(Dense(8, 'relu'))\n",
    "        model.add(Dense(1, 'linear'))\n",
    "        print(model.summary())\n",
    "        \n",
    "        # callbacks for checking validity\n",
    "        cb = ModelCheckpoint('model/', save_best_only=True)\n",
    "        model.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])\n",
    "        \n",
    "        # fitting the model\n",
    "        model.fit(self.tts['xtrain'], self.tts['ytrain'], validation_data=[self.tts['xval'], self.tts['yval']], epochs=epochs, callbacks=[cb])\n",
    "        \n",
    "        model = load_model('model/')\n",
    "        \n",
    "        if plot:\n",
    "            train_predictions = model.predict(self.tts['xtrain']).flatten()\n",
    "            train_results = pd.DataFrame(data={'Train predictions':train_predictions, 'Actuals':self.tts['ytrain']})\n",
    "            self.plotForecasting(train_results['Train predictions'], train_results['Actuals'])\n",
    "            \n",
    "            test_predictions = model.predict(self.tts['xtest']).flatten()\n",
    "            test_results = pd.DataFrame(data={'Test predictions':train_predictions, 'Actuals':self.tts['ytest']})\n",
    "            self.plotForecasting(train_results['Test predictions'], train_results['Actuals'])\n",
    "            \n",
    "            val_predictions = model.predict(self.tts['xval']).flatten()\n",
    "            val_results = pd.DataFrame(data={'Val predictions':train_predictions, 'Actuals':self.tts['yval']})\n",
    "            self.plotForecasting(train_results['Val predictions'], train_results['Actuals'])\n",
    "        \n",
    "        self.saveModel(model, 'lstmforecasting')\n",
    "        return model        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
